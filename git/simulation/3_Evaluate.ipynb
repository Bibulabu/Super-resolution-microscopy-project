{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jackc\\anaconda3\\envs\\SIM\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import skimage\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import scipy.ndimage as ndimage\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from skimage import io,exposure,img_as_ubyte\n",
    "import glob\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "from models import GetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadModel(opt):\n",
    "    print('Loading model')\n",
    "    print(opt)\n",
    "\n",
    "    net = GetModel(opt)\n",
    "    print('loading checkpoint',opt.weights)\n",
    "    checkpoint = torch.load(opt.weights,map_location=opt.device)\n",
    "\n",
    "    if type(checkpoint) is dict:\n",
    "        state_dict = checkpoint['state_dict']\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "\n",
    "    net.load_state_dict(state_dict)\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def SIM_reconstruct(model, opt):\n",
    "    \n",
    "    def prepimg(stack,self):\n",
    "\n",
    "        inputimg = stack[:9]\n",
    "\n",
    "        if self.nch_in == 6:\n",
    "            inputimg = inputimg[[0,1,3,4,6,7]]\n",
    "        elif self.nch_in == 3:\n",
    "            inputimg = inputimg[[0,4,8]]\n",
    "\n",
    "        if inputimg.shape[1] > 512 or inputimg.shape[2] > 512:\n",
    "            print('Over 512x512! Cropping')\n",
    "            inputimg = inputimg[:,:512,:512]\n",
    "\n",
    "        inputimg = inputimg.astype('float') / np.max(inputimg) # used to be /255\n",
    "        widefield = np.mean(inputimg,0) \n",
    "\n",
    "        if self.norm == 'adapthist':\n",
    "            for i in range(len(inputimg)):\n",
    "                inputimg[i] = exposure.equalize_adapthist(inputimg[i],clip_limit=0.001)\n",
    "            widefield = exposure.equalize_adapthist(widefield,clip_limit=0.001)\n",
    "            inputimg = torch.from_numpy(inputimg).float()\n",
    "            widefield = torch.from_numpy(widefield).float()\n",
    "        else:\n",
    "            # normalise \n",
    "            inputimg = torch.from_numpy(inputimg).float()\n",
    "            widefield = torch.from_numpy(widefield).float()\n",
    "            widefield = (widefield - torch.min(widefield)) / (torch.max(widefield) - torch.min(widefield))\n",
    "\n",
    "            if self.norm == 'minmax':\n",
    "                for i in range(len(inputimg)):\n",
    "                    inputimg[i] = (inputimg[i] - torch.min(inputimg[i])) / (torch.max(inputimg[i]) - torch.min(inputimg[i]))\n",
    "\n",
    "        return inputimg,widefield\n",
    "\n",
    "    os.makedirs('%s' % opt.out,exist_ok=True)\n",
    "    files = glob.glob('%s/*.tif' % opt.root)\n",
    "    \n",
    "    for iidx,imgfile in enumerate(files):\n",
    "        \n",
    "        print('[%d/%d] Reconstructing %s' % (iidx+1,len(files),imgfile))\n",
    "        stack = io.imread(imgfile)\n",
    "        \n",
    "        inputimg, wf = prepimg(stack,opt)\n",
    "        wf = (255*wf.numpy()).astype('uint8')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sr = model(inputimg.unsqueeze(0).to(opt.device))\n",
    "            sr = sr.cpu()\n",
    "            sr = torch.clamp(sr,min=0,max=1) \n",
    "\n",
    "        sr = sr.squeeze().numpy()\n",
    "        sr = (255*sr).astype('uint8')\n",
    "        if opt.norm == 'adapthist':\n",
    "            sr = exposure.equalize_adapthist(sr,clip_limit=0.01)\n",
    "\n",
    "        #skimage.io.imsave('%s/test_wf_%d.jpg' % (opt.out,iidx), wf)\n",
    "        #skimage.io.imsave('%s/test_sr_%d.jpg' % (opt.out,iidx), sr) \n",
    "        skimage.io.imsave('%s/sr_%d.jpg' % (opt.out,iidx), sr)\n",
    "        skimage.io.imsave('%s/wf_%d.jpg' % (opt.out,iidx), wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run example model trained with `2_Train.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = argparse.Namespace()\n",
    "\n",
    "opt.root = 'Test_data/microtubules_simulated'\n",
    "opt.out = 'Test_data/wf20.7'\n",
    "opt.task = 'simin_gtout'\n",
    "opt.norm = 'minmax'\n",
    "opt.dataset = 'fouriersim'\n",
    "\n",
    "opt.model = 'srr'\n",
    "\n",
    "# data\n",
    "opt.imageSize = 512\n",
    "opt.weights = 'Testbench/Best.pth'\n",
    "\n",
    "# input/output layer options\n",
    "opt.scale = 1\n",
    "opt.nch_in = 9\n",
    "opt.nch_out = 1\n",
    "\n",
    "# architecture options \n",
    "\"\"\" opt.narch = 0\n",
    "opt.n_resblocks = 3\n",
    "opt.n_resgroups = 5\n",
    "opt.reduction = 16\n",
    "opt.n_feats = 48 \"\"\"\n",
    "\n",
    "# test options\n",
    "opt.test = True\n",
    "opt.cpu = False\n",
    "opt.device = torch.device('cuda' if torch.cuda.is_available() and not opt.cpu else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n",
      "Namespace(root='Test_data/microtubules_simulated', out='Test_data/wf20.7', task='simin_gtout', norm='minmax', dataset='fouriersim', model='srr', imageSize=512, weights='Testbench/Best.pth', scale=1, nch_in=9, nch_out=1, test=True, cpu=False, device=device(type='cuda'))\n",
      "loading checkpoint Testbench/Best.pth\n",
      "[1/54] Reconstructing Test_data/microtubules_simulated\\000_0.tif\n",
      "[2/54] Reconstructing Test_data/microtubules_simulated\\001_0.tif\n",
      "[3/54] Reconstructing Test_data/microtubules_simulated\\002_0.tif\n",
      "[4/54] Reconstructing Test_data/microtubules_simulated\\003_0.tif\n",
      "[5/54] Reconstructing Test_data/microtubules_simulated\\004_0.tif\n",
      "[6/54] Reconstructing Test_data/microtubules_simulated\\005_0.tif\n",
      "[7/54] Reconstructing Test_data/microtubules_simulated\\006_0.tif\n",
      "[8/54] Reconstructing Test_data/microtubules_simulated\\007_0.tif\n",
      "[9/54] Reconstructing Test_data/microtubules_simulated\\008_0.tif\n",
      "[10/54] Reconstructing Test_data/microtubules_simulated\\009_0.tif\n",
      "[11/54] Reconstructing Test_data/microtubules_simulated\\010_0.tif\n",
      "[12/54] Reconstructing Test_data/microtubules_simulated\\011_0.tif\n",
      "[13/54] Reconstructing Test_data/microtubules_simulated\\012_0.tif\n",
      "[14/54] Reconstructing Test_data/microtubules_simulated\\013_0.tif\n",
      "[15/54] Reconstructing Test_data/microtubules_simulated\\014_0.tif\n",
      "[16/54] Reconstructing Test_data/microtubules_simulated\\015_0.tif\n",
      "[17/54] Reconstructing Test_data/microtubules_simulated\\016_0.tif\n",
      "[18/54] Reconstructing Test_data/microtubules_simulated\\017_0.tif\n",
      "[19/54] Reconstructing Test_data/microtubules_simulated\\018_0.tif\n",
      "[20/54] Reconstructing Test_data/microtubules_simulated\\019_0.tif\n",
      "[21/54] Reconstructing Test_data/microtubules_simulated\\020_0.tif\n",
      "[22/54] Reconstructing Test_data/microtubules_simulated\\021_0.tif\n",
      "[23/54] Reconstructing Test_data/microtubules_simulated\\022_0.tif\n",
      "[24/54] Reconstructing Test_data/microtubules_simulated\\023_0.tif\n",
      "[25/54] Reconstructing Test_data/microtubules_simulated\\024_0.tif\n",
      "[26/54] Reconstructing Test_data/microtubules_simulated\\025_0.tif\n",
      "[27/54] Reconstructing Test_data/microtubules_simulated\\026_0.tif\n",
      "[28/54] Reconstructing Test_data/microtubules_simulated\\027_0.tif\n",
      "[29/54] Reconstructing Test_data/microtubules_simulated\\028_0.tif\n",
      "[30/54] Reconstructing Test_data/microtubules_simulated\\029_0.tif\n",
      "[31/54] Reconstructing Test_data/microtubules_simulated\\030_0.tif\n",
      "[32/54] Reconstructing Test_data/microtubules_simulated\\031_0.tif\n",
      "[33/54] Reconstructing Test_data/microtubules_simulated\\032_0.tif\n",
      "[34/54] Reconstructing Test_data/microtubules_simulated\\033_0.tif\n",
      "[35/54] Reconstructing Test_data/microtubules_simulated\\034_0.tif\n",
      "[36/54] Reconstructing Test_data/microtubules_simulated\\035_0.tif\n",
      "[37/54] Reconstructing Test_data/microtubules_simulated\\036_0.tif\n",
      "[38/54] Reconstructing Test_data/microtubules_simulated\\037_0.tif\n",
      "[39/54] Reconstructing Test_data/microtubules_simulated\\038_0.tif\n",
      "[40/54] Reconstructing Test_data/microtubules_simulated\\039_0.tif\n",
      "[41/54] Reconstructing Test_data/microtubules_simulated\\040_0.tif\n",
      "[42/54] Reconstructing Test_data/microtubules_simulated\\041_0.tif\n",
      "[43/54] Reconstructing Test_data/microtubules_simulated\\042_0.tif\n",
      "[44/54] Reconstructing Test_data/microtubules_simulated\\043_0.tif\n",
      "[45/54] Reconstructing Test_data/microtubules_simulated\\044_0.tif\n",
      "[46/54] Reconstructing Test_data/microtubules_simulated\\045_0.tif\n",
      "[47/54] Reconstructing Test_data/microtubules_simulated\\046_0.tif\n",
      "[48/54] Reconstructing Test_data/microtubules_simulated\\047_0.tif\n",
      "[49/54] Reconstructing Test_data/microtubules_simulated\\048_0.tif\n",
      "[50/54] Reconstructing Test_data/microtubules_simulated\\049_0.tif\n",
      "[51/54] Reconstructing Test_data/microtubules_simulated\\050_0.tif\n",
      "[52/54] Reconstructing Test_data/microtubules_simulated\\051_0.tif\n",
      "[53/54] Reconstructing Test_data/microtubules_simulated\\052_0.tif\n",
      "[54/54] Reconstructing Test_data/microtubules_simulated\\053_0.tif\n"
     ]
    }
   ],
   "source": [
    "net = LoadModel(opt)\n",
    "SIM_reconstruct(net,opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.ntrain = 1 #设成多少都不影响\n",
    "opt.ntest = 54\n",
    "opt.batchSize = 1\n",
    "opt.batchSize_test = 1\n",
    "opt.workers = 2\n",
    "opt.nplot = 1\n",
    "\n",
    "if opt.test:\n",
    "        from datahandler import GetDataloaders\n",
    "        from plotting import testAndMakeCombinedPlots\n",
    "        \n",
    "        _, validloader = GetDataloaders(opt)\n",
    "        testAndMakeCombinedPlots(net, validloader, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run pre-trained model provided as a download file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download the model file at:\n",
    "    - https://ml-sim.s3.eu-west-2.amazonaws.com/pdist/models/DIV2K_randomised_3x3_20200317.pth\n",
    "- Put the downloaded model in the root folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" opt = argparse.Namespace()\n",
    "\n",
    "opt.root = 'Test_data'\n",
    "opt.out = 'test_output'\n",
    "opt.task = 'simin_gtout'\n",
    "opt.norm = 'minmax'\n",
    "opt.dataset = 'fouriersim'\n",
    "\n",
    "opt.model = 'rcan'\n",
    "\n",
    "# data\n",
    "opt.imageSize = 512\n",
    "opt.weights = 'DIV2K_randomised_3x3_20200317.pth'\n",
    "\n",
    "# input/output layer options\n",
    "opt.scale = 1\n",
    "opt.nch_in = 9\n",
    "opt.nch_out = 1\n",
    "\n",
    "# architecture options \n",
    "opt.n_resgroups = 3\n",
    "opt.n_resblocks = 10\n",
    "opt.n_feats = 96\n",
    "opt.reduction = 16\n",
    "opt.narch = 0\n",
    "\n",
    "# test options\n",
    "opt.test = False\n",
    "opt.cpu = False\n",
    "opt.device = torch.device('cuda' if torch.cuda.is_available() and not opt.cpu else 'cpu') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" net = LoadModel(opt)\n",
    "SIM_reconstruct(net,opt) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
